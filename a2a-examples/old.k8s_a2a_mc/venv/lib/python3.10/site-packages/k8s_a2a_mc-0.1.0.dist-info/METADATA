Metadata-Version: 2.4
Name: k8s-a2a-mc
Version: 0.1.0
Summary: Automated Kubernetes Pod CrashLoopBackOff Diagnosis using A2A and MCP
Requires-Python: >=3.10.12
Description-Content-Type: text/markdown
Requires-Dist: a2a-sdk>=0.1.0
Requires-Dist: mcp-sdk>=0.1.0
Requires-Dist: fastapi>=0.104.0
Requires-Dist: uvicorn>=0.23.2
Requires-Dist: pydantic>=2.4.2
Requires-Dist: google-generativeai>=0.3.0
Requires-Dist: kubernetes>=28.1.0
Requires-Dist: python-dotenv>=1.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.4.0; extra == "dev"
Requires-Dist: black>=23.7.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Requires-Dist: mypy>=1.5.1; extra == "dev"
Dynamic: requires-python


# Automated Kubernetes Pod CrashLoopBackOff Diagnosis

A comprehensive implementation of a Kubernetes troubleshooting system using Model Context Protocol (MCP) and Agent-to-Agent (A2A) communication to diagnose pods in CrashLoopBackOff state.

## Overview

This project demonstrates how to build an intelligent multi-agent system for automated Kubernetes troubleshooting using:

- **Model Context Protocol (MCP)**: For Kubernetes cluster interaction
- **Agent-to-Agent (A2A) Protocol**: For communication between specialized agents
- **Gemini AI**: For intelligent log analysis and troubleshooting synthesis

The system automatically diagnoses pods in CrashLoopBackOff state by collecting information from the Kubernetes cluster, analyzing logs, and generating comprehensive troubleshooting reports with recommendations.

## System Architecture

![System Architecture](https://mermaid.ink/img/pako:eNqNkk1PwzAMhv9KlBMIpq3dOk0TtzJx4AbiEJrGW6M1SZUPCab-d9KuMG0wDbnYfh37tZ04VlpxLHhpjHUPYLXcwxvUxjlQr9A6I6HVzVpCZ6RqYaOsAQcnUBK2YLXcQW8cKNkBOGugkxJ-wJEFKGmg1hKU6cB2Rlk4gNlD3TT1GpTqYKOVBFjBHVzDLVzBJSxhAQtYwC3M4QbmMJ_BbDaDq-l0Op3CYjKZTCZwPR6Px2O4GY1Go9ENLIej4XA4hOVgMBgM4HbQ7_f7fbgb9Hq9Xg_u-91ut9uFVafT6XTgvtNut9tteGg1m81mEx6bzWaz2YTHRqPRaECVa-fQbpXhXBTYWVnlGvZGPsEHbFXJhSiw0U6-f0rn0BRcCFwbVeXwrLfG8v9YiIKttdnzXJTY6F1VGm14gU_aVMZyIUt8qVWdy5wLWePKmJ3lQla4Nrbi-Ufj-AuXQcTl?type=png)

### Components

1. **Kubernetes MCP Server**: Exposes tools to run kubectl commands
2. **Kubernetes Info Agent**: MCP client and A2A server for pod information retrieval
3. **Log Analysis Agent**: Uses Gemini to analyze pod logs
4. **Orchestrator Agent**: Coordinates the troubleshooting workflow
5. **User Agent**: CLI interface for users

## Features

- **Automated Diagnosis**: Automatically diagnoses pods in CrashLoopBackOff state
- **Intelligent Log Analysis**: Uses Gemini AI to analyze logs and identify issues
- **Comprehensive Reports**: Generates detailed troubleshooting reports with recommendations
- **Multi-Agent Architecture**: Specialized agents for different tasks
- **Extensible Design**: Easy to add new tools and skills

## Prerequisites

- Python 3.10.12+
- Kubernetes v1.30.4+
- Access to a Kubernetes cluster with kubectl configured
- Gemini API key

## Quick Start

See the [Implementation Guide](./IMPLEMENTATION_GUIDE.md) for detailed setup and usage instructions.

```bash
# Install dependencies
pip install -e .

# Set up environment variables
cp .env.example .env
# Edit .env and add your Gemini API key

# Run all services
python main.py run-all

# In another terminal, troubleshoot a pod
python main.py troubleshoot -n default -p my-crashing-pod
```

## Testing

The project includes test scripts to deploy a pod in CrashLoopBackOff state and run the diagnosis system:

```bash
# Deploy a test pod and run the diagnosis
python test/run_full_test.py
```

### Scenario

A developer notices that a critical application pod in their Kubernetes cluster is repeatedly entering a `CrashLoopBackOff` state. They need to quickly identify the root cause, which could range from application errors, incorrect configuration, or resource limits.

### Agents Involved

1.  **User Agent (Client):** This is the interface the developer interacts with (e.g., a CLI tool or a simple web UI). It initiates the troubleshooting process.
2.  **Orchestrator Agent:** This agent acts as the central coordinator. It receives requests from the User Agent, delegates tasks to specialized agents, and aggregates their findings. It leverages Gemini for high-level reasoning and decision-making.
3.  **Kubernetes Info Agent:** This specialized agent is responsible for interacting with the Kubernetes API. It will use an MCP server to access `kubectl` commands and retrieve pod logs, events, and descriptions.
4.  **Log Analysis Agent:** This specialized agent analyzes logs provided by the Kubernetes Info Agent. It can use Gemini's text analysis capabilities to identify error patterns, stack traces, and potential issues.

### Protocol Flow

```mermaid
graph TD
    A[User Agent] -- "Troubleshoot Pod X" --> B(Orchestrator Agent);

    B -- "Request Pod Info (X)" --> C{Kubernetes Info Agent};
    C -- "MCP Request: kubectl get pod X -o yaml" --> D[Kubernetes MCP Server];
    D -- "kubectl output" --> C;
    C -- "A2A: Pod YAML, Events" --> B;

    B -- "A2A: Request Pod Logs (X)" --> C;
    C -- "MCP Request: kubectl logs X" --> D;
    D -- "Pod Logs" --> C;
    C -- "A2A: Pod Logs" --> E[Log Analysis Agent];
    E -- "Gemini: Analyze Logs" --> E;
    E -- "A2A: Log Analysis Report" --> B;

    B -- "Gemini: Synthesize findings & suggest remediation" --> B;
    B -- "A2A: Troubleshooting Report & Recommendation" --> A;
    A -- "Display Report" --> User[Developer];

```

## Detailed Breakdown and Implementation Concepts

### 1\. Model Context Protocol (MCP) for Kubernetes Interaction

The core of interacting with Kubernetes from your agents will be via an **MCP server**.

  * **Kubernetes MCP Server:** You'd set up an MCP server (refer to the `modelcontextprotocol/servers` GitHub repository for inspiration, specifically a `Filesystem` or a custom `kubectl` wrapper server). This server would expose tools for `kubectl` commands.

      * **Tools exposed:**
          * `get_pod_description(namespace: str, pod_name: str)`: Executes `kubectl get pod <pod_name> -n <namespace> -o yaml`.
          * `get_pod_events(namespace: str, pod_name: str)`: Executes `kubectl get events -n <namespace> --field-selector involvedObject.name=<pod_name>`.
          * `get_pod_logs(namespace: str, pod_name: str, container_name: str = None)`: Executes `kubectl logs <pod_name> -n <namespace> [-c <container_name>]`.

  * **Kubernetes Info Agent (MCP Client):** This agent will act as an MCP client. When the Orchestrator Agent requests Kubernetes information, the Kubernetes Info Agent will make a request to the local Kubernetes MCP server, invoking the appropriate `kubectl` tool.

      * **Example (conceptual):**
        ```python
        # Inside Kubernetes Info Agent
        from mcp_client import MCPClient

        k8s_mcp_client = MCPClient(server_url="http://localhost:8000/k8s-mcp") # Assuming your MCP server runs here

        async def get_pod_details(namespace, pod_name):
            # Calls the MCP server's exposed tool
            description = await k8s_mcp_client.call_tool("get_pod_description", namespace=namespace, pod_name=pod_name)
            events = await k8s_mcp_client.call_tool("get_pod_events", namespace=namespace, pod_name=pod_name)
            return description, events

        async def get_logs(namespace, pod_name, container_name=None):
            logs = await k8s_mcp_client.call_tool("get_pod_logs", namespace=namespace, pod_name=pod_name, container_name=container_name)
            return logs
        ```

### 2\. Agent-to-Agent (A2A) Communication

**A2A protocol** will be used for agents to communicate and delegate tasks.

  * **Agent Card:** Each agent will have an A2A "Agent Card" describing its capabilities (skills).

      * **Orchestrator Agent's Agent Card:** Might list "troubleshoot\_pod" as a skill.
      * **Kubernetes Info Agent's Agent Card:** Might list "retrieve\_k8s\_info", "get\_pod\_logs" as skills.
      * **Log Analysis Agent's Agent Card:** Might list "analyze\_logs" as a skill.

  * **Task Delegation:**

      * The **User Agent** sends a task (e.g., `{"task_id": "pod-troubleshoot-123", "skill": "troubleshoot_pod", "args": {"namespace": "my-app", "pod_name": "my-app-pod-xyz"}}`) to the **Orchestrator Agent**.
      * The **Orchestrator Agent**, after initial reasoning with Gemini, delegates tasks to the **Kubernetes Info Agent** (e.g., `{"task_id": "k8s-info-456", "skill": "retrieve_k8s_info", "args": {"namespace": "my-app", "pod_name": "my-app-pod-xyz"}}`).
      * The **Orchestrator Agent** then delegates log analysis to the **Log Analysis Agent** (e.g., `{"task_id": "log-analysis-789", "skill": "analyze_logs", "args": {"logs": "...", "pod_name": "my-app-pod-xyz"}}`).

  * **Response Handling:** Agents send back `StatusUpdate` messages via A2A to indicate progress and eventually `TaskCompletion` messages with results.

      * **Example (conceptual A2A interaction):**
        ```python
        # Inside Orchestrator Agent
        from a2a_sdk import A2AClient # Assuming A2A SDK is used

        k8s_agent_client = A2AClient(agent_url="http://localhost:8001/k8s-agent")
        log_agent_client = A2AClient(agent_url="http://localhost:8002/log-agent")

        async def orchestrate_troubleshooting(namespace, pod_name):
            # Step 1: Get K8s info
            k8s_task = await k8s_agent_client.send_task("retrieve_k8s_info", {"namespace": namespace, "pod_name": pod_name})
            k8s_result = await k8s_task.wait_for_completion()
            pod_yaml = k8s_result.artifacts["pod_yaml"]
            pod_events = k8s_result.artifacts["pod_events"]

            # Step 2: Get logs
            logs_task = await k8s_agent_client.send_task("get_pod_logs", {"namespace": namespace, "pod_name": pod_name})
            logs_result = await logs_task.wait_for_completion()
            pod_logs = logs_result.artifacts["logs"]

            # Step 3: Analyze logs
            analysis_task = await log_agent_client.send_task("analyze_logs", {"logs": pod_logs, "pod_name": pod_name})
            analysis_report = await analysis_task.wait_for_completion()
            log_findings = analysis_report.artifacts["findings"]

            # Step 4: Synthesize with Gemini (covered in next section)
            # ...
        ```

### 3\. Gemini Integration

**Gemini** will be the "brain" for intelligent reasoning at multiple stages.

  * **Orchestrator Agent (High-Level Reasoning):**
      * When the Orchestrator Agent receives the initial troubleshooting request, it can use Gemini to *interpret* the user's intent and formulate a plan.
      * After receiving information from the Kubernetes Info Agent (pod YAML, events) and the Log Analysis Agent (log findings), the Orchestrator Agent feeds all this context to Gemini.
      * **Gemini's Role:** Synthesize the pod description, events, and log analysis to identify the most probable cause of `CrashLoopBackOff` (e.g., "ImagePullBackOff due to incorrect image name", "OOMKilled due to high memory usage", "application crash indicated by specific error in logs"). It will then suggest concrete remediation steps (e.g., "Correct image name in deployment", "Increase memory limits in `resource.limits`", "Check application code for exceptions").
      * **Prompt Example for Orchestrator Agent:**
        ```
        "Analyze the following Kubernetes pod YAML, events, and log analysis findings to determine the root cause of the 'CrashLoopBackOff' state for pod '{pod_name}' in namespace '{namespace}'. Provide a concise explanation of the problem and actionable remediation steps.

        Pod YAML:
        {pod_yaml}

        Pod Events:
        {pod_events}

        Log Analysis Findings:
        {log_findings}
        "
        ```
  * **Log Analysis Agent (Detailed Log Parsing):**
      * The Log Analysis Agent will send the raw pod logs to Gemini.
      * **Gemini's Role:** Identify error messages, stack traces, repeated patterns, and crucial warnings within the logs. It can summarize the log content, extract key events, and even categorize error types.
      * **Prompt Example for Log Analysis Agent:**
        ```
        "Analyze the following logs from Kubernetes pod '{pod_name}' and identify any errors, warnings, or significant events that could explain a 'CrashLoopBackOff' state. Summarize your findings and extract any relevant error messages or stack traces.

        Logs:
        {pod_logs}
        "
        ```

## Setting Up Your Environment (High-Level Steps)

1.  **Clone `a2a-samples` and `modelcontextprotocol/servers`:**
    ```bash
    git clone https://github.com/a2aproject/a2a-samples.git
    git clone https://github.com/modelcontextprotocol/servers.git
    ```
2.  **Kubernetes MCP Server Setup:**
      * Navigate to `modelcontextprotocol/servers`.
      * You'll likely need to create a custom server or adapt an existing one (like the `Filesystem` server) to execute `kubectl` commands securely. This might involve wrapping `subprocess.run(['kubectl', ...])` calls within the server's tool functions.
      * **Crucial:** Ensure your MCP server has access to your Kubernetes configuration (`~/.kube/config`). When running in a container, this means mounting it.
      * Run the MCP server.
3.  **A2A Agents Setup:**
      * Refer to `a2a-samples` for examples of setting up A2A agents (e.g., `version_2_adk_agent` or `version_4_multi_agent_mcp` for inspiration on multi-agent setups).
      * **Orchestrator Agent:** This will be your main agent. It will need the Gemini API key to interact with the Gemini LLM. It will also act as an A2A client to the Kubernetes Info Agent and Log Analysis Agent.
      * **Kubernetes Info Agent:** This agent will be an A2A server and an MCP client. It will expose skills to the Orchestrator Agent and use its internal MCP client to call the Kubernetes MCP server.
      * **Log Analysis Agent:** This agent will be an A2A server. It will accept logs from the Orchestrator Agent and use the Gemini API (directly or via a wrapper) for log analysis.
4.  **Gemini API Key:** Ensure your agents that use Gemini (Orchestrator and Log Analysis Agents) have access to your Gemini API key, typically via environment variables.

### Considerations and Enhancements

  * **Error Handling:** Implement robust error handling for `kubectl` commands, MCP communication, and A2A messages.
  * **Security:** Be mindful of security. The Kubernetes MCP server should have the minimum necessary RBAC permissions in your cluster. Consider authentication and authorization for A2A communication.
  * **Context Management:** MCP helps with tool context, but for multi-turn troubleshooting conversations, agents might need persistent memory or state management.
  * **Tool Output Parsing:** Gemini is good at understanding natural language, but structured tool outputs (like JSON from `kubectl -o json`) are easier for agents to process reliably.
  * **Interactive Remediation:** The Orchestrator Agent could, after diagnosis, offer to *execute* the remediation steps if they involve simple `kubectl` commands (e.g., `kubectl apply -f updated-deployment.yaml`) by delegating back to the Kubernetes Info Agent. This would require more sophisticated `kubectl` tools in the MCP server.
  * **Metrics Agent:** You could add another agent, a "Metrics Agent," that uses MCP to interact with Prometheus or other monitoring systems to fetch relevant metrics (CPU, memory usage) when a `CrashLoopBackOff` occurs.

By building this example, you'll gain a strong understanding of how MCP provides tools to agents, how A2A enables agents to collaborate, and how Gemini can be leveraged for intelligent decision-making and analysis in a practical scenario like Kubernetes troubleshooting. Good luck\!
